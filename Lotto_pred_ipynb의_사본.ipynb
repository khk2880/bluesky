{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khk2880/bluesky/blob/main/Lotto_pred_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfb3c118",
      "metadata": {
        "id": "dfb3c118",
        "outputId": "0f525b4a-5738-4e22-9ba2-def57fd432e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#현재 폴더 경로; 작업 폴더 기준\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "i5wWH7aky9Ec",
        "outputId": "369f4aed-3737-41e1-f606-cdd7aba30705",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "i5wWH7aky9Ec",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1990801",
      "metadata": {
        "id": "d1990801",
        "outputId": "4fe04a76-cc8c-492c-8395-37147814457c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'lotto.csv', 'drive', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "print(os.listdir(os.getcwd()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd754802",
      "metadata": {
        "id": "cd754802",
        "outputId": "9852cb6d-32b8-4436-c693-8219f6ffb731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch    0 train acc 0.018 loss 0.406 val acc nan loss nan\n",
            "epoch    1 train acc 0.018 loss 0.396 val acc nan loss nan\n",
            "epoch    2 train acc 0.021 loss 0.394 val acc nan loss nan\n",
            "epoch    3 train acc 0.020 loss 0.392 val acc nan loss nan\n",
            "epoch    4 train acc 0.018 loss 0.389 val acc nan loss nan\n",
            "epoch    5 train acc 0.023 loss 0.385 val acc nan loss nan\n",
            "epoch    6 train acc 0.026 loss 0.380 val acc nan loss nan\n",
            "epoch    7 train acc 0.038 loss 0.375 val acc nan loss nan\n",
            "epoch    8 train acc 0.046 loss 0.369 val acc nan loss nan\n",
            "epoch    9 train acc 0.045 loss 0.363 val acc nan loss nan\n",
            "epoch   10 train acc 0.049 loss 0.356 val acc nan loss nan\n",
            "epoch   11 train acc 0.051 loss 0.349 val acc nan loss nan\n",
            "epoch   12 train acc 0.061 loss 0.341 val acc nan loss nan\n",
            "epoch   13 train acc 0.070 loss 0.333 val acc nan loss nan\n",
            "epoch   14 train acc 0.081 loss 0.323 val acc nan loss nan\n",
            "epoch   15 train acc 0.089 loss 0.313 val acc nan loss nan\n",
            "epoch   16 train acc 0.101 loss 0.302 val acc nan loss nan\n",
            "epoch   17 train acc 0.103 loss 0.291 val acc nan loss nan\n",
            "epoch   18 train acc 0.111 loss 0.280 val acc nan loss nan\n",
            "epoch   19 train acc 0.115 loss 0.270 val acc nan loss nan\n",
            "epoch   20 train acc 0.113 loss 0.258 val acc nan loss nan\n",
            "epoch   21 train acc 0.125 loss 0.248 val acc nan loss nan\n",
            "epoch   22 train acc 0.128 loss 0.237 val acc nan loss nan\n",
            "epoch   23 train acc 0.129 loss 0.228 val acc nan loss nan\n",
            "epoch   24 train acc 0.137 loss 0.218 val acc nan loss nan\n",
            "epoch   25 train acc 0.129 loss 0.208 val acc nan loss nan\n",
            "epoch   26 train acc 0.141 loss 0.199 val acc nan loss nan\n",
            "epoch   27 train acc 0.145 loss 0.192 val acc nan loss nan\n",
            "epoch   28 train acc 0.132 loss 0.183 val acc nan loss nan\n",
            "epoch   29 train acc 0.127 loss 0.180 val acc nan loss nan\n",
            "epoch   30 train acc 0.151 loss 0.171 val acc nan loss nan\n",
            "epoch   31 train acc 0.137 loss 0.164 val acc nan loss nan\n",
            "epoch   32 train acc 0.164 loss 0.160 val acc nan loss nan\n",
            "epoch   33 train acc 0.140 loss 0.153 val acc nan loss nan\n",
            "epoch   34 train acc 0.146 loss 0.145 val acc nan loss nan\n",
            "epoch   35 train acc 0.148 loss 0.140 val acc nan loss nan\n",
            "epoch   36 train acc 0.142 loss 0.134 val acc nan loss nan\n",
            "epoch   37 train acc 0.124 loss 0.125 val acc nan loss nan\n",
            "epoch   38 train acc 0.132 loss 0.125 val acc nan loss nan\n",
            "epoch   39 train acc 0.154 loss 0.122 val acc nan loss nan\n",
            "epoch   40 train acc 0.165 loss 0.115 val acc nan loss nan\n",
            "epoch   41 train acc 0.146 loss 0.115 val acc nan loss nan\n",
            "epoch   42 train acc 0.155 loss 0.109 val acc nan loss nan\n",
            "epoch   43 train acc 0.148 loss 0.101 val acc nan loss nan\n",
            "epoch   44 train acc 0.154 loss 0.102 val acc nan loss nan\n",
            "epoch   45 train acc 0.142 loss 0.095 val acc nan loss nan\n",
            "epoch   46 train acc 0.144 loss 0.092 val acc nan loss nan\n",
            "epoch   47 train acc 0.142 loss 0.091 val acc nan loss nan\n",
            "epoch   48 train acc 0.149 loss 0.084 val acc nan loss nan\n",
            "epoch   49 train acc 0.158 loss 0.082 val acc nan loss nan\n",
            "receive numbers\n",
            "0 : [3, 7, 13, 14, 35, 37]\n",
            "1 : [3, 14, 20, 33, 35, 37]\n",
            "2 : [3, 5, 14, 17, 20, 44]\n",
            "3 : [7, 14, 29, 35, 37, 39]\n",
            "4 : [3, 11, 14, 20, 35, 43]\n"
          ]
        }
      ],
      "source": [
        "# 데이터 다운로드\n",
        "import numpy as np\n",
        "rows = np.loadtxt(\"lotto.csv\", delimiter=\",\")\n",
        "row_count = len(rows)\n",
        "\n",
        "# 당첨번호를 원핫인코딩벡터(ohbin)으로 변환\n",
        "def numbers2ohbin(numbers):\n",
        "\n",
        "    ohbin = np.zeros(45) #45개의 빈 칸을 만듬\n",
        "\n",
        "    for i in range(6): #여섯개의 당첨번호에 대해서 반복함\n",
        "        ohbin[int(numbers[i])-1] = 1 #로또번호가 1부터 시작하지만 벡터의 인덱스 시작은 0부터 시작하므로 1을 뺌\n",
        "    \n",
        "    return ohbin\n",
        "\n",
        "# 원핫인코딩벡터(ohbin)를 번호로 변환\n",
        "def ohbin2numbers(ohbin):\n",
        "\n",
        "    numbers = []\n",
        "    \n",
        "    for i in range(len(ohbin)):\n",
        "        if ohbin[i] == 1.0: # 1.0으로 설정되어 있으면 해당 번호를 반환값에 추가한다.\n",
        "            numbers.append(i+1)\n",
        "    \n",
        "    return numbers\n",
        "    \n",
        "numbers = rows[:, 1:7]\n",
        "ohbins = list(map(numbers2ohbin, numbers))\n",
        "\n",
        "x_samples = ohbins[0:row_count-1]\n",
        "y_samples = ohbins[1:row_count]\n",
        "# 데이터 나누기\n",
        "train_idx = (0, 1028)\n",
        "# val_idx = (1027, 1028)\n",
        "# test_idx = (1029, len(x_samples))\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "# 모델을 정의합니다.\n",
        "model = keras.Sequential([\n",
        "    keras.layers.LSTM(128, batch_input_shape=(1, 1, 45), return_sequences=False, stateful=True),\n",
        "    keras.layers.Dense(45, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 모델을 컴파일합니다.\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 매 에포크마다 훈련과 검증의 손실 및 정확도를 기록하기 위한 변수\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "val_loss = []\n",
        "val_acc = []\n",
        "\n",
        "# 최대 100번 에포크까지 수행\n",
        "for epoch in range(50):\n",
        "\n",
        "    model.reset_states() # 중요! 매 에포크마다 1회부터 다시 훈련하므로 상태 초기화 필요\n",
        "\n",
        "    batch_train_loss = []\n",
        "    batch_train_acc = []\n",
        "    \n",
        "    for i in range(train_idx[0], train_idx[1]):\n",
        "        \n",
        "        xs = x_samples[i].reshape(1, 1, 45)\n",
        "        ys = y_samples[i].reshape(1, 45)\n",
        "        \n",
        "        loss, acc = model.train_on_batch(xs, ys) #배치만큼 모델에 학습시킴\n",
        "\n",
        "        batch_train_loss.append(loss)\n",
        "        batch_train_acc.append(acc)\n",
        "\n",
        "    train_loss.append(np.mean(batch_train_loss))\n",
        "    train_acc.append(np.mean(batch_train_acc))\n",
        "\n",
        "    batch_val_loss = []\n",
        "    batch_val_acc = []\n",
        "\n",
        "#     for i in range(val_idx[0], val_idx[1]):\n",
        "\n",
        "#         xs = x_samples[i].reshape(1, 1, 45)\n",
        "#         ys = y_samples[i].reshape(1, 45)\n",
        "        \n",
        "#         loss, acc = model.test_on_batch(xs, ys) #배치만큼 모델에 입력하여 나온 답을 정답과 비교함\n",
        "        \n",
        "#         batch_val_loss.append(loss)\n",
        "#         batch_val_acc.append(acc)\n",
        "\n",
        "#     val_loss.append(np.mean(batch_val_loss))\n",
        "#     val_acc.append(np.mean(batch_val_acc))\n",
        "\n",
        "    print('epoch {0:4d} train acc {1:0.3f} loss {2:0.3f} val acc {3:0.3f} loss {4:0.3f}'.format(epoch, np.mean(batch_train_acc), np.mean(batch_train_loss), np.mean(batch_val_acc), np.mean(batch_val_loss)))\n",
        "    # 번호 뽑기\n",
        "def gen_numbers_from_probability(nums_prob):\n",
        "\n",
        "    ball_box = []\n",
        "\n",
        "    for n in range(45):\n",
        "        ball_count = int(nums_prob[n] * 100 + 1)\n",
        "        ball = np.full((ball_count), n+1) #1부터 시작\n",
        "        ball_box += list(ball)\n",
        "\n",
        "    selected_balls = []\n",
        "\n",
        "    while True:\n",
        "        \n",
        "        if len(selected_balls) == 6:\n",
        "            break\n",
        "        \n",
        "        ball_index = np.random.randint(len(ball_box), size=1)[0]\n",
        "        ball = ball_box[ball_index]\n",
        "\n",
        "        if ball not in selected_balls:\n",
        "            selected_balls.append(ball)\n",
        "\n",
        "    return selected_balls\n",
        "    \n",
        "print('receive numbers')\n",
        "\n",
        "xs = x_samples[-1].reshape(1, 1, 45)\n",
        "\n",
        "ys_pred = model.predict_on_batch(xs)\n",
        "\n",
        "list_numbers = []\n",
        "\n",
        "for n in range(5):\n",
        "    numbers = gen_numbers_from_probability(ys_pred[0])\n",
        "    numbers.sort()\n",
        "    print('{0} : {1}'.format(n, numbers))\n",
        "    list_numbers.append(numbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58aed3cd",
      "metadata": {
        "id": "58aed3cd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}